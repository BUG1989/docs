:::tip
This document is intended to demonstrate how to run the official example, for more information please see [RKNN Toolkit2](https://github.com/rockchip-linux/rknn-toolkit2) doc directory.
:::

<Tabs queryString="target">

<TabItem value="pc" label="RKNN Toolkit on PC">

## Install dependencies

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
sudo apt install git python-is-python3 python3-pip libxslt1-dev zlib1g-dev libglib2.0-dev libsm6 libgl1-mesa-glx libprotobuf-dev build-essential adb
```

</NewCodeBlock>

## Download and installing RKNN Toolkit2

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
git clone -b v2.3.0 https://github.com/airockchip/rknn-toolkit2.git
cd rknn-toolkit2/rknn-toolkit2/packages/x86_64/
pip3 install -r requirements_cp38-2.3.0.txt
pip3 install ./rknn_toolkit2-2.3.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl
```

</NewCodeBlock>

## Run the yolov5 example

<NewCodeBlock tip="X86 Linux PC" type="PC">

```bash
cd examples/onnx/yolov5
python test.py
```

</NewCodeBlock>

:::info
After the conversion model and inference script test.py is run successfully, the converted model is saved in examples/onnx/yolov5/yolov5s_relu.rknn by default, and the result of the inference image is saved in examples/onnx/yolov5/result.jpg
:::

![inference result](/img/general-tutorial/rknn/result.webp)

</TabItem>

<TabItem value="board" label="RKNN Toolkit on board">

:::tip
For users of RK356X products, you need to enable the NPU in the terminal using **rsetup** before using the NPU: `sudo rsetup -> Overlays -> Manage overlays -> Enable NPU`, then restart the system.

If there is no `Enable NPU` option in the overlays options, please update the system via: `sudo rsetup -> system -> System Update`, restart, and execute the above steps to enable the NPU.
:::

## Install RKNN Toolkit Lite2 and dependencies

:::info
RKNN Toolkit Lite2 and its dependencies are installed by default in the official Radxa system image, if it does not work, try the following commands.
:::

<NewCodeBlock tip="Radxa OS" type="device">

```bash
sudo apt update
sudo apt install rknpu2-rk3588 python3-rknnlite2    #SOC is RK3588 series
sudo apt install rknpu2-rk356x python3-rknnlite2    #SOC is RK356X series
```

</NewCodeBlock>

## Install RKNN Toolkit Lite2 example

<NewCodeBlock tip="Radxa OS" type="device">

```bash
sudo apt update
sudo apt install python3-rknnlite2-example
```

</NewCodeBlock>

## Running the Resnet18 example

:::info
RKNN Toolkit Lite2 is mainly used for deploying RKNN models on Rockchip NPU.
Before using the RKNN Toolkit Lite2, we need to convert the exported models of each framework into RKNN models through RKNN Toolkit2 on PC.
:::

<NewCodeBlock tip="Radxa OS" type="device">

```bash
cd /usr/share/python3-rknnlite2/resnet18
python3 test.py
```

</NewCodeBlock>

<NewCodeBlock tip="Results" type="device">

```bash
--> Load RKNN model
done
--> Init runtime environment
I RKNN: [14:34:53.240] RKNN Runtime Information: librknnrt version: 1.5.2 (c6b7b351a@2023-08-23T15:28:22)
I RKNN: [14:34:53.242] RKNN Driver Information: version: 0.8.2
W RKNN: [14:34:53.242] Current driver version: 0.8.2, recommend to upgrade the driver to the new version: >= 0.8.8
I RKNN: [14:34:53.250] RKNN Model Information: version: 6, toolkit version: 1.5.2-source_code(compiler version: 1.5.2 (71720f3fc@2023-08-21T09:35:42)), target: RKNPU v2, target platform: rk3588, framework name: PyTorch, framework layout: NCHW, model inference type: static_shape
done
--> Running model
resnet18
-----TOP 5-----
[812]: 0.9996760487556458
[404]: 0.00024927023332566023
[657]: 1.449744013370946e-05
[466 833]: 9.023910024552606e-06
[466 833]: 9.023910024552606e-06

done
```

</NewCodeBlock>

:::info
Executing this example will load the Resnet18 model and perform inference to get the top5 classification results for the test image.
Here, category 812 has the highest probability, so the model may think that the input image belongs to category 812.
To understand what category 812 represents, we need to look at the dataset or labels that were used in the training of the model, or look for documents or resources related to the model to determine what category 812 means.
In this case category 812 would represent the space shuttle.
:::

![Input image](/img/general-tutorial/rknn/space_shuttle_224.webp)

</TabItem>

</Tabs>
